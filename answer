1) What is the definition of Hive? What is the present version of Hive?
answer :- hive is dataware house which will run on top of hadoop.
present version is hive 3.1.3.

2) Is Hive suitable to be used for OLTP systems? Why?
answer:-- No Hive does not provide insert and update at row level. So it is not suitable for OLTP system.

3) How is HIVE different from RDBMS? Does hive support ACID transactions. If not then give the proper reason.
answer:-- hive is only of used for maintain data warehouse.
it will run on HQL .Hive supports ACID transactions on tables that store ORC file format.

4)Explain the hive architecture and the different components of a Hive architecture?
hive architecture.
-----------------

1)multiple clients like thrift app, jdbc app, odbc app.

2)client will gives data to driver .
3)driver to compiler 
4)driver to metastore
5)driver to optimizer.
6) the driver output goes to mapreduce and yarn part.
7)map reduces, yarn  (resource management and processing)
8)mapreduce to hdfs part file receives
9)last is hdfs this is for storage of file

5)Mention what Hive query processor does? And Mention what are the components of a Hive query processor?
answer:-- Hive query processor convert graph of MapReduce jobs with the execution time framework.
Parse and Semantic Analysis (ql/parse)
Metadata Layer (ql/metadata)
Type Interfaces (ql/typeinfo)
Sessions (ql/session)
Map/Reduce Execution Engine (ql/exec)
Plan Components (ql/plan)
Hive Function Framework (ql/udf)
Tools (ql/tools).

6) what are the 3 modes in which we can operate hive?
answer:-- Standalone Mode.
Pseudo-distributed Mode.
Fully-Distributed Mode.

7) What are the features and limitations of hive?
 answer:--
Limitations of Hive
Hive doesn't support OLTP. Hive supports Online Analytical Processing (OLAP), but not Online Transaction Processing (OLTP).
It doesn't support subqueries.
It has a high latency.
Hive's Features
Hive is designed for querying and managing only structured data stored in tables.
Hive is scalable, fast, and uses familiar concepts.
Schema gets stored in a database, while processed data goes into a Hadoop Distributed File System (HDFS)

8) How to create a Database in HIVE?
answer:-- create database name.

9) How to create a table in HIVE?
answer:-- create table name( id, name etc).
row format delimited .
fields terminated by some limitation;

10) What do you mean by describe and describe extended and describe
formatted with respect to database and table.
answer:--
describe extended - This will show table columns, data types, and other details of the table. 
Other details will be displayed in single line.
describe formatted - This will show table columns, data types, and other details of the table.
Other details will be displayed into multiple lines

11)How to skip header rows from a table in Hive?
answer:-- by using tabular properties like 
tbl properties("skip.header.line.count"= "1")

12)What is a hive operator? What are the different types of hive operators?
answer:-- Hive operators are used for mathematical operations on operands. It returns specific value as per the logic applied.
There are four types of operators in Hive:
Relational Operators.
Arithmetic Operators.
Logical Operators.
Complex Operators.

13) 13.Explain about the Hive Built-In Functions
answer:-- The Hive Built-in functions are categorized as Mathematical function, Collection function, Type conversion function, Date function, Conditional function, and String function. 

14)write hive DDL and DML commands.
The various Hive DML commands are:
LOAD.
SELECT.
INSERT.
DELETE.
UPDATE.

The several types of Hive DDL commands are:
CREATE.
SHOW.
DESCRIBE.
USE.
DROP.
ALTER.
EXPORT.
IMPORT.
TRUNCATE.

15)15.Explain about SORT BY, ORDER BY, DISTRIBUTE BY and
CLUSTER BY in Hive.
answer:-- sort by:
That means the files are sorted per reducer basis only, and not globally. 
Note that the final output data is not globally sorted and may have overlapping data ranges.

order by :
ORDER BY clause orders the data globally.
Because it ensures the global ordering of the data, all the data need to be passed from a single reducer only.

distribute by:
DISTRIBUTE BY clause is used to distribute the input rows among reducers. 
It ensures that all rows for the same key columns are going to the same reducer. 
the DISTRIBUTE BY clause may output N number of unsorted files where N is the number of reducers used in the query processing.
But, the output files do not contain overlapping data ranges.

clusterby:
CLUSTER BY clause is a combination of DISTRIBUTE BY and SORT BY clauses together.
That means the output of the CLUSTER BY clause is equivalent to the output of DISTRIBUTE BY + SORT BY clauses. 
As a result, the order by clause outputs one single file only. 

16) Difference between "Internal Table" and "External Table" and Mention
when to choose “Internal Table” and “External Table” in Hive?
answer:--internal table 
   if we table metadata will be stored in meta store 
	data of the table will be stored in warehouse directory inside hdfs configured for hive.
	if we drop a internal table then its metadata & original data both,will be removed
2)external table:---
  meta data will be stored in metastore.
	raw data will not be stored in hive warehouse directory but it will stored in hdfs location .
	it is like external reference to the raw data.
	if we remove the table then only metadata will be deleted but original data will be untouched .
  
  We create an external table for external use as when we want to use the data outside the Hive.
  External tables are stored outside the warehouse directory. They can access data stored in sources such as remote HDFS locations or Azure Storage Volumes
  
  internal hive 
  Use INTERNAL tables when: The data is temporary. You want Hive to completely manage the lifecycle of the table and data.
  
  17) Where does the data of a Hive table get stored?
  answer:-- Hive stores its database and table metadata in a metastore,
  
  18) Is it possible to change the default location of a managed table?
  answer:- yes  we can change the location of managed table in hive by giving location path .
  
  19) What is a metastore in Hive? What is the default database provided by
Apache Hive for metastore?

answer:-- Metastore is the central repository of Apache Hive metadata. It stores metadata for Hive tables 
Derby is the default database for the embedded metastore.

20) Why does Hive not store metadata information in HDFS?
answer:-- Hive stores metadata information in the metastore using RDBMS instead of HDFS.
21).What is a partition in Hive? And Why do we perform partitioning in
Hive?
answer:--
partition in hive :--- it is away of dividing table into related parts based on the values of aparticular column.
 the data is stored in slices, the query response time becomes faster.
 
 22) What is the difference between dynamic partitioning and static partitioning?
answer:-- dynamic partition
**  here column values will be unknown to us 
** hive will identify the unique value from partitioned column.
**it takes longer time while loading the data.
static partition:-
** here value of partition column will be known to us .
** we load the data in a specific partition .
** static partition takes less time. while loading data

23) How do you check if a particular partition exists?
answer:-- SHOW PARTITIONS table_name 
PARTITION(partitioned_column=’partition_value’)

24) How can you stop a partition form being queried?
answer:--By using the ENABLE OFFLINE clause with ALTER TABLE atatement.

25) Why do we need buckets? How Hive distributes the rows into buckets?
answer:--
Bucketing in hive is useful when dealing with large datasets 
that may need to be segregated into clusters for more efficient management and to be able to perform join queries with other large datasets
based on the hashing technique.

26) In Hive, how can you enable buckets?
answer:-- set.hive.enforce.bucketing=true;

27) How does bucketing help in the faster execution of queries?
answer:-- Bucketing improves performance by shuffling and sorting data prior to downstream operations such as table joins.

28)  How to optimise Hive Performance? Explain in very detail.
answer :-- 
First, tweak your data through partitioning, bucketing, compression, etc.
Improving the execution of a hive query is another Hive query optimization technique.
You can do this by using Tez, avoiding skew, and increasing parallel execution.

29) What is the use of Hcatalog?
answer:- HCatalog is a tool that allows you to access Hive metastore tables within Pig, Spark SQL, and/or custom MapReduce applications.

30) Explain about the different types of join in Hive.
answer:-- there are several types of Hive join –
Hive inner join, hive left outer join, hive right outer join, and hive full outer join.

31) Is it possible to create a Cartesian join between 2 tables, using Hive?
 answer:-- Cross join, also known as Cartesian product, 
 is a way of joining multiple tables in which all the rows or tuples from one table are paired with the rows and tuples from another table.
 
 32) Explain the SMB Join in Hive?
 answer:-- SMB is a join performed on bucket tables that have the same sorted, bucket, and join condition columns.
 It reads data from both bucket tables and performs common joins (map and reduce triggered) on the bucket tables.
 
 33) What is the difference between order by and sort by which one we should use?
 answer:-- The difference between "order by" and "sort by" is that the former guarantees 
 total order in the output while the latter only guarantees ordering of the rows within a reducer.
 If there are more than one reducer, "sort by" may give partially ordered final results
 
 34) What is the usefulness of the DISTRIBUTED BY clause in Hive?
 answer:-- DISTRIBUTE BY clause is used to distribute the input rows among reducers.
 It ensures that all rows for the same key columns are going to the same reducer.
 So, if we need to partition the data on some key column, we can use the DISTRIBUTE BY clause in the hive queries.
 
 35) How does data transfer happen from HDFS to Hive?
 answer:-- You create a single Sqoop import command that imports data from diverse data sources, such as a relational database, into HDFS.
 Convert the data to ORC format. To query data in HDFS in Hive, you apply a schema to the data and then store data in ORC format.
 Incrementally update the imported data
